{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvhcQNOK1ZLz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from collections import OrderedDict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Sequential, Conv2d, MaxPool2d, ReLU, Flatten, Linear, MSELoss\n",
        "from torch.optim import Adam\n",
        "from torchinfo import summary\n",
        "\n",
        "\n",
        "class DQN(nn.Module):\n",
        "\n",
        "    def __init__(self, model_path='models/rl/model.pt'):\n",
        "        super().__init__()\n",
        "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "        self.model = None\n",
        "        self.optimizer = None\n",
        "        self.criterion = None\n",
        "        self.model_path = model_path\n",
        "\n",
        "    def build_model(self, n_stacked_frames, n_actions, learning_rate):\n",
        "\n",
        "\n",
        "       # Architecture proposed in https://arxiv.org/abs/1312.5602\n",
        "\n",
        "        self.model = Sequential(OrderedDict([\n",
        "        ('conv_1', Conv2d(in_channels=n_stacked_frames, out_channels=16, kernel_size=(4, 4), stride=(4, 4))),\n",
        "        ('activation_1', ReLU()),\n",
        "        ('conv_2', Conv2d(in_channels=16, out_channels=32, kernel_size=(4, 4), stride=(2, 2))),\n",
        "        ('activation_2', ReLU()),\n",
        "        ('flatten', Flatten()),\n",
        "        ('linear_1', Linear(in_features=2592, out_features=256)),\n",
        "        ('activation_4', ReLU()),\n",
        "        ('linear_2', Linear(in_features=256, out_features=n_actions))]))\n",
        "\n",
        "        self.optimizer = Adam(lr=learning_rate, params=self.model.parameters())\n",
        "        self.criterion = MSELoss()\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        # create model file if not present\n",
        "        if not os.path.isfile(self.model_path):\n",
        "            self.save_model()\n",
        "\n",
        "    def print_model(self):\n",
        "        summary(model=self.model, input_size=(1, 4, 80, 80))\n",
        "\n",
        "    def predict(self, state):\n",
        "        return self.model(state.float().to(self.device))\n",
        "\n",
        "    def train_on_batch(self, batch, gamma):\n",
        "\n",
        "        target_q_values = torch.tensor([]).to(self.device)\n",
        "        s_t1_q_values = torch.tensor([]).to(self.device)\n",
        "\n",
        "        for s_t, a_t, r_t, s_t1, done in batch:\n",
        "\n",
        "            target = self.predict(s_t)  # Predicted Q values\n",
        "            q_s_t1 = self.predict(s_t1)  # Predicted Q values for the next state\n",
        "\n",
        "            if done:\n",
        "                target[:, a_t] = r_t  # If terminated, only equals to reward\n",
        "            else:\n",
        "                target[:, a_t] = r_t + gamma * torch.max(q_s_t1)\n",
        "\n",
        "            target_q_values = torch.cat((target_q_values, target), dim=0)\n",
        "            s_t1_q_values = torch.cat((s_t1_q_values, q_s_t1), dim=0)\n",
        "\n",
        "        loss = self.criterion(target_q_values, s_t1_q_values)\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return loss.item()\n",
        "\n",
        "    def save_model(self):\n",
        "\n",
        "        print('Saving model')\n",
        "        torch.save({\n",
        "            'state_dict': self.model.state_dict(),\n",
        "            'optimizer': self.optimizer.state_dict(),\n",
        "        }, self.model_path)\n",
        "\n",
        "    def load_model(self, training=False):\n",
        "\n",
        "        state = torch.load(self.model_path)\n",
        "\n",
        "        if training:\n",
        "            print('Loading model to continue training')\n",
        "            self.model.load_state_dict(state['state_dict'])\n",
        "            self.optimizer.load_state_dict(state['optimizer'])\n",
        "            self.model.train()\n",
        "        else:\n",
        "            print('Loading model for inference')\n",
        "            self.model.load_state_dict(state['state_dict'])\n",
        "            self.model.eval()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "d4026d7a36d874e1f6c487603191095e1ef70b08516b0a096b0ced5fbd321bb0"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
